{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of our *neuron_layer* function, we could have used *tf.layers.dense*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.92 Val accuracy: 0.9118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Batch accuracy: 0.9 Val accuracy: 0.9312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Batch accuracy: 0.96 Val accuracy: 0.9396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Batch accuracy: 1.0 Val accuracy: 0.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Batch accuracy: 0.98 Val accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Batch accuracy: 0.98 Val accuracy: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Batch accuracy: 0.96 Val accuracy: 0.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Batch accuracy: 0.96 Val accuracy: 0.9598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Batch accuracy: 1.0 Val accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Batch accuracy: 0.98 Val accuracy: 0.9662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Batch accuracy: 0.98 Val accuracy: 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Batch accuracy: 0.96 Val accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Batch accuracy: 0.96 Val accuracy: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Batch accuracy: 1.0 Val accuracy: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Batch accuracy: 0.96 Val accuracy: 0.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Batch accuracy: 0.98 Val accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Batch accuracy: 0.98 Val accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Batch accuracy: 1.0 Val accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Batch accuracy: 0.98 Val accuracy: 0.9728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Batch accuracy: 1.0 Val accuracy: 0.9754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Batch accuracy: 0.96 Val accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Batch accuracy: 0.96 Val accuracy: 0.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Batch accuracy: 1.0 Val accuracy: 0.9748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Batch accuracy: 1.0 Val accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Batch accuracy: 0.98 Val accuracy: 0.9742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Batch accuracy: 1.0 Val accuracy: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Batch accuracy: 0.96 Val accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Batch accuracy: 0.98 Val accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Batch accuracy: 0.98 Val accuracy: 0.9772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Batch accuracy: 1.0 Val accuracy: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Batch accuracy: 0.98 Val accuracy: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Batch accuracy: 1.0 Val accuracy: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Batch accuracy: 1.0 Val accuracy: 0.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Batch accuracy: 0.98 Val accuracy: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Batch accuracy: 1.0 Val accuracy: 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Batch accuracy: 1.0 Val accuracy: 0.9788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Batch accuracy: 1.0 Val accuracy: 0.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Batch accuracy: 1.0 Val accuracy: 0.9772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Batch accuracy: 1.0 Val accuracy: 0.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Batch accuracy: 1.0 Val accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"saved_models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_models/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"saved_models/my_model_final.ckpt\")  # or better, use save_path\n",
    "    X_new_scaled = X_test[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\nActual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Actual classes:   \", y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: 5\nActual classes:    5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 15\n",
    "plt.imshow(np.reshape(X_test[index], (28, 28)))\n",
    "print(\"Predicted classes:\", y_pred[index])\n",
    "print(\"Actual classes:   \", y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
