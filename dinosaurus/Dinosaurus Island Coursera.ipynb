{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import shuffle\n",
    "#https://gist.github.com/danijar/d11c77c5565482e965d1919291044470\n",
    "#https://github.com/crestonbunch/neural-namer/blob/master/modeler/network.py\n",
    "#https://danijar.com/variable-sequence-lengths-in-tensorflow/\n",
    "#https://r2rt.com/recurrent-neural-networks-in-tensorflow-iii-variable-length-sequences.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19909 total characters and 27 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "data = open('dinos.txt', 'r').read()\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_one_vector(word, char_to_ix, paddTo = 0):\n",
    "    one_hot_vectors = np.zeros((len(word), len(char_to_ix)))\n",
    "    one_hot_vectors[ np.arange(len(word)) , [char_to_ix[ch] for ch in word] ]= 1\n",
    "    if paddTo > 0:\n",
    "        one_hot_vectors = np.vstack((one_hot_vectors, np.zeros((paddTo - len(word), len(char_to_ix)))))\n",
    "    return one_hot_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dinos.txt\") as f:\n",
    "    examples = f.readlines()\n",
    "examples = [x.lower().strip() for x in examples]\n",
    "\n",
    "max_length = 0\n",
    "for x in examples:\n",
    "    if len(x) > max_length:\n",
    "        max_length = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 200\n",
    "n_steps = max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, None, vocab_size])\n",
    "y = tf.placeholder(tf.int32, [None, None]) #Shape => Batch_Size x Steps\n",
    "seq_len = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units =  n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype = tf.float32, sequence_length = seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_outputs = tf.reshape(outputs, [-1, n_neurons])\n",
    "stacked_outputs_dense = tf.layers.dense(stacked_outputs, vocab_size)\n",
    "outputs_2 = tf.reshape(stacked_outputs_dense, [-1, seq_len, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = outputs_2)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_examples = np.empty((len(examples), max_length , vocab_size))\n",
    "y_examples = np.empty((len(examples), max_length ))\n",
    "\n",
    "first_item = np.zeros(len(char_to_ix))\n",
    "first_item[1] = 1\n",
    "\n",
    "for iter_number, example  in enumerate(examples):\n",
    "    x_ = np.vstack((word_to_one_vector(example, char_to_ix, max_length)))\n",
    "    X_examples[iter_number] = x_\n",
    "    #x_ = x_.reshape(1, x_.shape[0], x_.shape[1])\n",
    "    y_ = np.asarray([(char_to_ix[x]) for x in example[1:]])\n",
    "    y_ = np.append(y_, np.zeros((max_length - len(example) + 1)))\n",
    "    #y_ = y_.reshape(1, y_.shape[0])\n",
    "    y_examples[iter_number] = y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.285091\n",
      "wgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "lgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "qgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "kgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "igegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "ugegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "\n",
      "\n",
      "100 1.450628\n",
      "igegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "qgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "as\n",
      "cgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "cgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "lgegegegegegegegegegegegegegegegegegegegegegegegege\n",
      "\n",
      "\n",
      "200 1.3415786\n",
      "ugeasususususususususususususususususususususususus\n",
      "jgeasususususususususususususususususususususususus\n",
      "asususususususususususususususususususususususususu\n",
      "ggeasususususususususususususususususususususususus\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(50000):\n",
    "        sess.run(training_op, feed_dict = {X: X_examples, y: y_examples, seq_len: max_length})\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, loss.eval(feed_dict = {X: X_examples, y: y_examples, seq_len: max_length}))\n",
    "            for x in range(6):\n",
    "                word = []\n",
    "                x = np.zeros((vocab_size)).reshape(-1, 1, vocab_size)\n",
    "                x[0,0,1] = np.random.randint(vocab_size)\n",
    "                word.append(ix_to_char[x[0,0,1]])\n",
    "                for iter_number in range(50):\n",
    "                    out = sess.run(outputs_2, feed_dict = {X: x, seq_len: 1})\n",
    "                    indexs = tf.nn.softmax(out).eval().reshape(-1, vocab_size)\n",
    "                    choice = tf.argmax(indexs[0]).eval()\n",
    "                    #choice = np.random.choice(range(vocab_size), p = indexs[0])\n",
    "                    if choice == 0:\n",
    "                        break\n",
    "                    word.append(ix_to_char[choice])\n",
    "                    x = np.zeros((vocab_size))\n",
    "                    x[choice] = 1\n",
    "                    x = x.reshape(-1, 1, vocab_size)\n",
    "                word = ''.join(word) \n",
    "                print(word)\n",
    "            print(\"\\n\")\n",
    "    #shuffle(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
